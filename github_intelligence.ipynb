{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3329d1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘¨â€ðŸ’» GITHUB DEVELOPER INTELLIGENCE ANALYSIS\n",
      "==================================================\n",
      "Using real GitHub API data to track developer adoption signals\n",
      "Alternative data approach for predicting software company performance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M Science Analysis - Part 2B: GitHub Developer Intelligence\n",
    "# Real Alternative Data from GitHub API - Developer Adoption Signals\n",
    "# Predicting Software Company Performance Through Developer Community Health\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"ðŸ‘¨â€ðŸ’» GITHUB DEVELOPER INTELLIGENCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Using real GitHub API data to track developer adoption signals\")\n",
    "print(\"Alternative data approach for predicting software company performance\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88aea6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Setting up GitHub API connection...\n",
      "ðŸ“ Note: Using unauthenticated API (60 requests/hour limit)\n",
      "   For production: Add GitHub token for 5000 requests/hour\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. GITHUB API SETUP & COMPANY MAPPING\n",
    "# =============================================================================\n",
    "\n",
    "# Charles Rogers' coverage companies mapped to their GitHub presence\n",
    "COMPANY_GITHUB_MAPPING = {\n",
    "    # Cloud Infrastructure & DevTools\n",
    "    'MDB': {\n",
    "        'name': 'MongoDB',\n",
    "        'ticker': 'MDB',\n",
    "        'main_repo': 'mongodb/mongo',\n",
    "        'additional_repos': ['mongodb/mongoid', 'mongodb/node-mongodb-native', 'mongodb/motor'],\n",
    "        'org': 'mongodb',\n",
    "        'category': 'Database'\n",
    "    },\n",
    "    'NET': {\n",
    "        'name': 'Cloudflare',\n",
    "        'ticker': 'NET', \n",
    "        'main_repo': 'cloudflare/workers-sdk',\n",
    "        'additional_repos': ['cloudflare/cloudflare-go', 'cloudflare/terraform-provider-cloudflare', 'cloudflare/wrangler'],\n",
    "        'org': 'cloudflare',\n",
    "        'category': 'CDN/Edge'\n",
    "    },\n",
    "    'GTLB': {\n",
    "        'name': 'GitLab',\n",
    "        'ticker': 'GTLB',\n",
    "        'main_repo': 'gitlabhq/gitlabhq',\n",
    "        'additional_repos': ['gitlab-org/gitlab-runner', 'gitlab-org/gitlab-foss'],\n",
    "        'org': 'gitlabhq',\n",
    "        'category': 'DevOps'\n",
    "    },\n",
    "    'DOCN': {\n",
    "        'name': 'DigitalOcean',\n",
    "        'ticker': 'DOCN',\n",
    "        'main_repo': 'digitalocean/doctl',\n",
    "        'additional_repos': ['digitalocean/terraform-provider-digitalocean', 'digitalocean/sample-django'],\n",
    "        'org': 'digitalocean',\n",
    "        'category': 'Cloud Platform'\n",
    "    },\n",
    "    'TEAM': {\n",
    "        'name': 'Atlassian',\n",
    "        'ticker': 'TEAM',\n",
    "        'main_repo': 'atlassian/react-beautiful-dnd',\n",
    "        'additional_repos': ['atlassian/atlaskit-mk-2', 'atlassian/design-system'],\n",
    "        'org': 'atlassian',\n",
    "        'category': 'DevTools'\n",
    "    },\n",
    "    'AKAM': {\n",
    "        'name': 'Akamai',\n",
    "        'ticker': 'AKAM',\n",
    "        'main_repo': 'akamai/cli',\n",
    "        'additional_repos': ['akamai/terraform-provider-akamai', 'akamai/boomerang'],\n",
    "        'org': 'akamai',\n",
    "        'category': 'CDN'\n",
    "    },\n",
    "    'FSLY': {\n",
    "        'name': 'Fastly',\n",
    "        'ticker': 'FSLY',\n",
    "        'main_repo': 'fastly/cli',\n",
    "        'additional_repos': ['fastly/terraform-provider-fastly', 'fastly/compute-starter-kit-javascript-default'],\n",
    "        'org': 'fastly',\n",
    "        'category': 'CDN/Edge'\n",
    "    }\n",
    "}\n",
    "\n",
    "# GitHub API configuration\n",
    "GITHUB_API_BASE = 'https://api.github.com'\n",
    "# Note: For production, you'd want to add your GitHub token for higher rate limits\n",
    "# GITHUB_TOKEN = 'your_token_here'  # 5000 requests/hour with token vs 60 without\n",
    "\n",
    "def get_github_data(endpoint, params=None):\n",
    "    \"\"\"\n",
    "    Fetch data from GitHub API with error handling and rate limiting\n",
    "    \"\"\"\n",
    "    url = f\"{GITHUB_API_BASE}/{endpoint}\"\n",
    "    headers = {\n",
    "        'Accept': 'application/vnd.github.v3+json',\n",
    "        'User-Agent': 'M-Science-Analysis'\n",
    "    }\n",
    "    \n",
    "    # Add token if available (uncomment if you have a token)\n",
    "    # if 'GITHUB_TOKEN' in globals():\n",
    "    #     headers['Authorization'] = f'token {GITHUB_TOKEN}'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 403:\n",
    "            print(f\"âš ï¸  Rate limited. Waiting 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ Error fetching {endpoint}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"ðŸ”§ Setting up GitHub API connection...\")\n",
    "print(\"ðŸ“ Note: Using unauthenticated API (60 requests/hour limit)\")\n",
    "print(\"   For production: Add GitHub token for 5000 requests/hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c2a0b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "1ï¸âƒ£  COLLECTING GITHUB REPOSITORY INTELLIGENCE\n",
      "============================================================\n",
      "\n",
      "ðŸ¢ MongoDB (MDB) - Database\n",
      "   ðŸ“Š Analyzing mongodb/mongo...\n",
      "   ðŸ“Š Analyzing mongodb/mongoid...\n",
      "   ðŸ“Š Analyzing mongodb/node-mongodb-native...\n",
      "\n",
      "ðŸ¢ Cloudflare (NET) - CDN/Edge\n",
      "   ðŸ“Š Analyzing cloudflare/workers-sdk...\n",
      "   ðŸ“Š Analyzing cloudflare/cloudflare-go...\n",
      "   ðŸ“Š Analyzing cloudflare/terraform-provider-cloudflare...\n",
      "\n",
      "ðŸ¢ GitLab (GTLB) - DevOps\n",
      "   ðŸ“Š Analyzing gitlabhq/gitlabhq...\n",
      "   ðŸ“Š Analyzing gitlab-org/gitlab-runner...\n",
      "âŒ Error fetching repos/gitlab-org/gitlab-runner: 404 Client Error: Not Found for url: https://api.github.com/repos/gitlab-org/gitlab-runner\n",
      "   ðŸ“Š Analyzing gitlab-org/gitlab-foss...\n",
      "âŒ Error fetching repos/gitlab-org/gitlab-foss: 404 Client Error: Not Found for url: https://api.github.com/repos/gitlab-org/gitlab-foss\n",
      "\n",
      "ðŸ¢ DigitalOcean (DOCN) - Cloud Platform\n",
      "   ðŸ“Š Analyzing digitalocean/doctl...\n",
      "   ðŸ“Š Analyzing digitalocean/terraform-provider-digitalocean...\n",
      "   ðŸ“Š Analyzing digitalocean/sample-django...\n",
      "\n",
      "ðŸ¢ Atlassian (TEAM) - DevTools\n",
      "   ðŸ“Š Analyzing atlassian/react-beautiful-dnd...\n",
      "   ðŸ“Š Analyzing atlassian/atlaskit-mk-2...\n",
      "âŒ Error fetching repos/atlassian/atlaskit-mk-2: 404 Client Error: Not Found for url: https://api.github.com/repos/atlassian/atlaskit-mk-2\n",
      "   ðŸ“Š Analyzing atlassian/design-system...\n",
      "âŒ Error fetching repos/atlassian/design-system: 404 Client Error: Not Found for url: https://api.github.com/repos/atlassian/design-system\n",
      "\n",
      "ðŸ¢ Akamai (AKAM) - CDN\n",
      "   ðŸ“Š Analyzing akamai/cli...\n",
      "   ðŸ“Š Analyzing akamai/terraform-provider-akamai...\n",
      "   ðŸ“Š Analyzing akamai/boomerang...\n",
      "\n",
      "ðŸ¢ Fastly (FSLY) - CDN/Edge\n",
      "   ðŸ“Š Analyzing fastly/cli...\n",
      "âš ï¸  Rate limited. Waiting 60 seconds...\n",
      "âŒ Error fetching repos/fastly/cli: 403 Client Error: rate limit exceeded for url: https://api.github.com/repos/fastly/cli\n",
      "   ðŸ“Š Analyzing fastly/terraform-provider-fastly...\n",
      "âš ï¸  Rate limited. Waiting 60 seconds...\n",
      "   ðŸ“Š Analyzing fastly/compute-starter-kit-javascript-default...\n",
      "\n",
      "âœ… Collected data for 7 companies\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. REPOSITORY INTELLIGENCE COLLECTION\n",
    "# =============================================================================\n",
    "\n",
    "def collect_repo_intelligence(repo_path):\n",
    "    \"\"\"\n",
    "    Collect comprehensive intelligence about a GitHub repository\n",
    "    \"\"\"\n",
    "    print(f\"   ðŸ“Š Analyzing {repo_path}...\")\n",
    "    \n",
    "    # Get basic repository information\n",
    "    repo_data = get_github_data(f'repos/{repo_path}')\n",
    "    if not repo_data:\n",
    "        return None\n",
    "    \n",
    "    # Get contributor statistics (limited by API rate limits)\n",
    "    contributors_data = get_github_data(f'repos/{repo_path}/contributors', {'per_page': 30})\n",
    "    \n",
    "    # Get recent releases\n",
    "    releases_data = get_github_data(f'repos/{repo_path}/releases', {'per_page': 10})\n",
    "    \n",
    "    # Get issue statistics\n",
    "    issues_data = get_github_data(f'repos/{repo_path}/issues', {'state': 'all', 'per_page': 1})\n",
    "    \n",
    "    # Calculate derived metrics\n",
    "    intelligence = {\n",
    "        'repo': repo_path,\n",
    "        'stars': repo_data.get('stargazers_count', 0),\n",
    "        'forks': repo_data.get('forks_count', 0),\n",
    "        'watchers': repo_data.get('watchers_count', 0),\n",
    "        'open_issues': repo_data.get('open_issues_count', 0),\n",
    "        'size_kb': repo_data.get('size', 0),\n",
    "        'created_at': repo_data.get('created_at'),\n",
    "        'updated_at': repo_data.get('updated_at'),\n",
    "        'pushed_at': repo_data.get('pushed_at'),\n",
    "        'language': repo_data.get('language'),\n",
    "        'has_wiki': repo_data.get('has_wiki', False),\n",
    "        'has_projects': repo_data.get('has_projects', False),\n",
    "        'archived': repo_data.get('archived', False),\n",
    "        'disabled': repo_data.get('disabled', False),\n",
    "        'contributors_count': len(contributors_data) if contributors_data else 0,\n",
    "        'recent_releases': len(releases_data) if releases_data else 0,\n",
    "        'fork_to_star_ratio': repo_data.get('forks_count', 0) / max(repo_data.get('stargazers_count', 1), 1),\n",
    "        'activity_score': 0  # Will calculate based on recent activity\n",
    "    }\n",
    "    \n",
    "    # Calculate activity score based on recent updates\n",
    "    try:\n",
    "        last_push = datetime.fromisoformat(repo_data.get('pushed_at', '').replace('Z', '+00:00'))\n",
    "        days_since_push = (datetime.now(last_push.tzinfo) - last_push).days\n",
    "        intelligence['days_since_last_push'] = days_since_push\n",
    "        intelligence['activity_score'] = max(0, 100 - days_since_push)  # Score decreases with inactivity\n",
    "    except:\n",
    "        intelligence['days_since_last_push'] = 999\n",
    "        intelligence['activity_score'] = 0\n",
    "    \n",
    "    # Add a small delay to respect rate limits\n",
    "    time.sleep(1)\n",
    "    \n",
    "    return intelligence\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1ï¸âƒ£  COLLECTING GITHUB REPOSITORY INTELLIGENCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect data for all companies\n",
    "company_github_data = {}\n",
    "\n",
    "for ticker, company_info in COMPANY_GITHUB_MAPPING.items():\n",
    "    print(f\"\\nðŸ¢ {company_info['name']} ({ticker}) - {company_info['category']}\")\n",
    "    \n",
    "    company_repos = []\n",
    "    \n",
    "    # Analyze main repository\n",
    "    main_repo_data = collect_repo_intelligence(company_info['main_repo'])\n",
    "    if main_repo_data:\n",
    "        main_repo_data['repo_type'] = 'main'\n",
    "        company_repos.append(main_repo_data)\n",
    "    \n",
    "    # Analyze additional repositories (limit to 2 to manage rate limits)\n",
    "    for additional_repo in company_info['additional_repos'][:2]:\n",
    "        additional_repo_data = collect_repo_intelligence(additional_repo)\n",
    "        if additional_repo_data:\n",
    "            additional_repo_data['repo_type'] = 'additional'\n",
    "            company_repos.append(additional_repo_data)\n",
    "    \n",
    "    company_github_data[ticker] = {\n",
    "        'company_info': company_info,\n",
    "        'repositories': company_repos\n",
    "    }\n",
    "\n",
    "print(f\"\\nâœ… Collected data for {len(company_github_data)} companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d5bc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2ï¸âƒ£  CALCULATING DEVELOPER ADOPTION METRICS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Developer Adoption Rankings:\n",
      "     company ticker  main_repo_stars  total_contributors  avg_activity_score       category\n",
      "     MongoDB    MDB            27372                  90           99.666667       Database\n",
      "   Atlassian   TEAM            34004                  30           93.000000       DevTools\n",
      "      GitLab   GTLB            24037                  30          100.000000         DevOps\n",
      "  Cloudflare    NET             3308                  69          100.000000       CDN/Edge\n",
      "DigitalOcean   DOCN             3333                  66           69.333333 Cloud Platform\n",
      "      Akamai   AKAM              223                  90           33.333333            CDN\n",
      "      Fastly   FSLY              122                  44           95.000000       CDN/Edge\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. DEVELOPER ADOPTION METRICS CALCULATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2ï¸âƒ£  CALCULATING DEVELOPER ADOPTION METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def calculate_company_metrics(ticker, data):\n",
    "    \"\"\"\n",
    "    Calculate aggregate metrics for a company across all repositories\n",
    "    \"\"\"\n",
    "    repos = data['repositories']\n",
    "    if not repos:\n",
    "        return None\n",
    "    \n",
    "    # Find main repository metrics\n",
    "    main_repo = next((r for r in repos if r['repo_type'] == 'main'), repos[0])\n",
    "    \n",
    "    # Aggregate metrics across all repositories\n",
    "    total_stars = sum(r['stars'] for r in repos)\n",
    "    total_forks = sum(r['forks'] for r in repos)\n",
    "    total_contributors = sum(r['contributors_count'] for r in repos)\n",
    "    avg_activity_score = np.mean([r['activity_score'] for r in repos])\n",
    "    \n",
    "    # Calculate developer engagement quality\n",
    "    engagement_quality = np.mean([r['fork_to_star_ratio'] for r in repos])\n",
    "    \n",
    "    # Calculate ecosystem health (number of active repositories)\n",
    "    active_repos = len([r for r in repos if r['activity_score'] > 50])\n",
    "    \n",
    "    return {\n",
    "        'ticker': ticker,\n",
    "        'company': data['company_info']['name'],\n",
    "        'category': data['company_info']['category'],\n",
    "        'main_repo_stars': main_repo['stars'],\n",
    "        'main_repo_forks': main_repo['forks'],\n",
    "        'main_repo_contributors': main_repo['contributors_count'],\n",
    "        'total_stars': total_stars,\n",
    "        'total_forks': total_forks,\n",
    "        'total_contributors': total_contributors,\n",
    "        'avg_activity_score': avg_activity_score,\n",
    "        'engagement_quality': engagement_quality,\n",
    "        'active_repositories': active_repos,\n",
    "        'ecosystem_size': len(repos),\n",
    "        'main_language': main_repo.get('language', 'Unknown'),\n",
    "        'days_since_last_push': main_repo['days_since_last_push'],\n",
    "        'developer_momentum': total_stars / max(1, main_repo['days_since_last_push'] / 30)  # Stars per month equivalent\n",
    "    }\n",
    "\n",
    "# Calculate metrics for all companies\n",
    "company_metrics = []\n",
    "for ticker, data in company_github_data.items():\n",
    "    metrics = calculate_company_metrics(ticker, data)\n",
    "    if metrics:\n",
    "        company_metrics.append(metrics)\n",
    "\n",
    "# Create DataFrame for analysis\n",
    "df_github = pd.DataFrame(company_metrics)\n",
    "df_github = df_github.sort_values('total_stars', ascending=False)\n",
    "\n",
    "print(f\"\\nðŸ“Š Developer Adoption Rankings:\")\n",
    "display_cols = ['company', 'ticker', 'main_repo_stars', 'total_contributors', 'avg_activity_score', 'category']\n",
    "print(df_github[display_cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956842ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
