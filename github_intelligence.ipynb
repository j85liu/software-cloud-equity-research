{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3329d1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë®‚Äçüíª GITHUB DEVELOPER INTELLIGENCE ANALYSIS\n",
      "==================================================\n",
      "Using real GitHub API data to track developer adoption signals\n",
      "Alternative data approach for predicting software company performance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M Science Analysis - Part 2B: GitHub Developer Intelligence\n",
    "# Real Alternative Data from GitHub API - Developer Adoption Signals\n",
    "# Predicting Software Company Performance Through Developer Community Health\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"üë®‚Äçüíª GITHUB DEVELOPER INTELLIGENCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Using real GitHub API data to track developer adoption signals\")\n",
    "print(\"Alternative data approach for predicting software company performance\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88aea6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Setting up GitHub API connection...\n",
      "üìù Note: Using unauthenticated API (60 requests/hour limit)\n",
      "   For production: Add GitHub token for 5000 requests/hour\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. GITHUB API SETUP & COMPANY MAPPING\n",
    "# =============================================================================\n",
    "\n",
    "# Charles Rogers' coverage companies mapped to their GitHub presence\n",
    "COMPANY_GITHUB_MAPPING = {\n",
    "    # Cloud Infrastructure & DevTools\n",
    "    'MDB': {\n",
    "        'name': 'MongoDB',\n",
    "        'ticker': 'MDB',\n",
    "        'main_repo': 'mongodb/mongo',\n",
    "        'additional_repos': ['mongodb/mongoid', 'mongodb/node-mongodb-native', 'mongodb/motor'],\n",
    "        'org': 'mongodb',\n",
    "        'category': 'Database'\n",
    "    },\n",
    "    'NET': {\n",
    "        'name': 'Cloudflare',\n",
    "        'ticker': 'NET', \n",
    "        'main_repo': 'cloudflare/workers-sdk',\n",
    "        'additional_repos': ['cloudflare/cloudflare-go', 'cloudflare/terraform-provider-cloudflare', 'cloudflare/wrangler'],\n",
    "        'org': 'cloudflare',\n",
    "        'category': 'CDN/Edge'\n",
    "    },\n",
    "    'GTLB': {\n",
    "        'name': 'GitLab',\n",
    "        'ticker': 'GTLB',\n",
    "        'main_repo': 'gitlabhq/gitlabhq',\n",
    "        'additional_repos': ['gitlab-org/gitlab-runner', 'gitlab-org/gitlab-foss'],\n",
    "        'org': 'gitlabhq',\n",
    "        'category': 'DevOps'\n",
    "    },\n",
    "    'DOCN': {\n",
    "        'name': 'DigitalOcean',\n",
    "        'ticker': 'DOCN',\n",
    "        'main_repo': 'digitalocean/doctl',\n",
    "        'additional_repos': ['digitalocean/terraform-provider-digitalocean', 'digitalocean/sample-django'],\n",
    "        'org': 'digitalocean',\n",
    "        'category': 'Cloud Platform'\n",
    "    },\n",
    "    'TEAM': {\n",
    "        'name': 'Atlassian',\n",
    "        'ticker': 'TEAM',\n",
    "        'main_repo': 'atlassian/react-beautiful-dnd',\n",
    "        'additional_repos': ['atlassian/atlaskit-mk-2', 'atlassian/design-system'],\n",
    "        'org': 'atlassian',\n",
    "        'category': 'DevTools'\n",
    "    },\n",
    "    'AKAM': {\n",
    "        'name': 'Akamai',\n",
    "        'ticker': 'AKAM',\n",
    "        'main_repo': 'akamai/cli',\n",
    "        'additional_repos': ['akamai/terraform-provider-akamai', 'akamai/boomerang'],\n",
    "        'org': 'akamai',\n",
    "        'category': 'CDN'\n",
    "    },\n",
    "    'FSLY': {\n",
    "        'name': 'Fastly',\n",
    "        'ticker': 'FSLY',\n",
    "        'main_repo': 'fastly/cli',\n",
    "        'additional_repos': ['fastly/terraform-provider-fastly', 'fastly/compute-starter-kit-javascript-default'],\n",
    "        'org': 'fastly',\n",
    "        'category': 'CDN/Edge'\n",
    "    }\n",
    "}\n",
    "\n",
    "# GitHub API configuration\n",
    "GITHUB_API_BASE = 'https://api.github.com'\n",
    "# Note: For production, you'd want to add your GitHub token for higher rate limits\n",
    "# GITHUB_TOKEN = 'your_token_here'  # 5000 requests/hour with token vs 60 without\n",
    "\n",
    "def get_github_data(endpoint, params=None):\n",
    "    \"\"\"\n",
    "    Fetch data from GitHub API with error handling and rate limiting\n",
    "    \"\"\"\n",
    "    url = f\"{GITHUB_API_BASE}/{endpoint}\"\n",
    "    headers = {\n",
    "        'Accept': 'application/vnd.github.v3+json',\n",
    "        'User-Agent': 'M-Science-Analysis'\n",
    "    }\n",
    "    \n",
    "    # Add token if available (uncomment if you have a token)\n",
    "    # if 'GITHUB_TOKEN' in globals():\n",
    "    #     headers['Authorization'] = f'token {GITHUB_TOKEN}'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 403:\n",
    "            print(f\"‚ö†Ô∏è  Rate limited. Waiting 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error fetching {endpoint}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"üîß Setting up GitHub API connection...\")\n",
    "print(\"üìù Note: Using unauthenticated API (60 requests/hour limit)\")\n",
    "print(\"   For production: Add GitHub token for 5000 requests/hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c2a0b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "1Ô∏è‚É£  COLLECTING GITHUB REPOSITORY INTELLIGENCE\n",
      "============================================================\n",
      "\n",
      "üè¢ MongoDB (MDB) - Database\n",
      "   üìä Analyzing mongodb/mongo...\n",
      "   üìä Analyzing mongodb/mongoid...\n",
      "   üìä Analyzing mongodb/node-mongodb-native...\n",
      "\n",
      "üè¢ Cloudflare (NET) - CDN/Edge\n",
      "   üìä Analyzing cloudflare/workers-sdk...\n",
      "   üìä Analyzing cloudflare/cloudflare-go...\n",
      "   üìä Analyzing cloudflare/terraform-provider-cloudflare...\n",
      "\n",
      "üè¢ GitLab (GTLB) - DevOps\n",
      "   üìä Analyzing gitlabhq/gitlabhq...\n",
      "   üìä Analyzing gitlab-org/gitlab-runner...\n",
      "‚ùå Error fetching repos/gitlab-org/gitlab-runner: 404 Client Error: Not Found for url: https://api.github.com/repos/gitlab-org/gitlab-runner\n",
      "   üìä Analyzing gitlab-org/gitlab-foss...\n",
      "‚ùå Error fetching repos/gitlab-org/gitlab-foss: 404 Client Error: Not Found for url: https://api.github.com/repos/gitlab-org/gitlab-foss\n",
      "\n",
      "üè¢ DigitalOcean (DOCN) - Cloud Platform\n",
      "   üìä Analyzing digitalocean/doctl...\n",
      "   üìä Analyzing digitalocean/terraform-provider-digitalocean...\n",
      "   üìä Analyzing digitalocean/sample-django...\n",
      "\n",
      "üè¢ Atlassian (TEAM) - DevTools\n",
      "   üìä Analyzing atlassian/react-beautiful-dnd...\n",
      "   üìä Analyzing atlassian/atlaskit-mk-2...\n",
      "‚ùå Error fetching repos/atlassian/atlaskit-mk-2: 404 Client Error: Not Found for url: https://api.github.com/repos/atlassian/atlaskit-mk-2\n",
      "   üìä Analyzing atlassian/design-system...\n",
      "‚ùå Error fetching repos/atlassian/design-system: 404 Client Error: Not Found for url: https://api.github.com/repos/atlassian/design-system\n",
      "\n",
      "üè¢ Akamai (AKAM) - CDN\n",
      "   üìä Analyzing akamai/cli...\n",
      "   üìä Analyzing akamai/terraform-provider-akamai...\n",
      "   üìä Analyzing akamai/boomerang...\n",
      "\n",
      "üè¢ Fastly (FSLY) - CDN/Edge\n",
      "   üìä Analyzing fastly/cli...\n",
      "‚ö†Ô∏è  Rate limited. Waiting 60 seconds...\n",
      "‚ùå Error fetching repos/fastly/cli: 403 Client Error: rate limit exceeded for url: https://api.github.com/repos/fastly/cli\n",
      "   üìä Analyzing fastly/terraform-provider-fastly...\n",
      "‚ö†Ô∏è  Rate limited. Waiting 60 seconds...\n",
      "   üìä Analyzing fastly/compute-starter-kit-javascript-default...\n",
      "\n",
      "‚úÖ Collected data for 7 companies\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. REPOSITORY INTELLIGENCE COLLECTION\n",
    "# =============================================================================\n",
    "\n",
    "def collect_repo_intelligence(repo_path):\n",
    "    \"\"\"\n",
    "    Collect comprehensive intelligence about a GitHub repository\n",
    "    \"\"\"\n",
    "    print(f\"   üìä Analyzing {repo_path}...\")\n",
    "    \n",
    "    # Get basic repository information\n",
    "    repo_data = get_github_data(f'repos/{repo_path}')\n",
    "    if not repo_data:\n",
    "        return None\n",
    "    \n",
    "    # Get contributor statistics (limited by API rate limits)\n",
    "    contributors_data = get_github_data(f'repos/{repo_path}/contributors', {'per_page': 30})\n",
    "    \n",
    "    # Get recent releases\n",
    "    releases_data = get_github_data(f'repos/{repo_path}/releases', {'per_page': 10})\n",
    "    \n",
    "    # Get issue statistics\n",
    "    issues_data = get_github_data(f'repos/{repo_path}/issues', {'state': 'all', 'per_page': 1})\n",
    "    \n",
    "    # Calculate derived metrics\n",
    "    intelligence = {\n",
    "        'repo': repo_path,\n",
    "        'stars': repo_data.get('stargazers_count', 0),\n",
    "        'forks': repo_data.get('forks_count', 0),\n",
    "        'watchers': repo_data.get('watchers_count', 0),\n",
    "        'open_issues': repo_data.get('open_issues_count', 0),\n",
    "        'size_kb': repo_data.get('size', 0),\n",
    "        'created_at': repo_data.get('created_at'),\n",
    "        'updated_at': repo_data.get('updated_at'),\n",
    "        'pushed_at': repo_data.get('pushed_at'),\n",
    "        'language': repo_data.get('language'),\n",
    "        'has_wiki': repo_data.get('has_wiki', False),\n",
    "        'has_projects': repo_data.get('has_projects', False),\n",
    "        'archived': repo_data.get('archived', False),\n",
    "        'disabled': repo_data.get('disabled', False),\n",
    "        'contributors_count': len(contributors_data) if contributors_data else 0,\n",
    "        'recent_releases': len(releases_data) if releases_data else 0,\n",
    "        'fork_to_star_ratio': repo_data.get('forks_count', 0) / max(repo_data.get('stargazers_count', 1), 1),\n",
    "        'activity_score': 0  # Will calculate based on recent activity\n",
    "    }\n",
    "    \n",
    "    # Calculate activity score based on recent updates\n",
    "    try:\n",
    "        last_push = datetime.fromisoformat(repo_data.get('pushed_at', '').replace('Z', '+00:00'))\n",
    "        days_since_push = (datetime.now(last_push.tzinfo) - last_push).days\n",
    "        intelligence['days_since_last_push'] = days_since_push\n",
    "        intelligence['activity_score'] = max(0, 100 - days_since_push)  # Score decreases with inactivity\n",
    "    except:\n",
    "        intelligence['days_since_last_push'] = 999\n",
    "        intelligence['activity_score'] = 0\n",
    "    \n",
    "    # Add a small delay to respect rate limits\n",
    "    time.sleep(1)\n",
    "    \n",
    "    return intelligence\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1Ô∏è‚É£  COLLECTING GITHUB REPOSITORY INTELLIGENCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect data for all companies\n",
    "company_github_data = {}\n",
    "\n",
    "for ticker, company_info in COMPANY_GITHUB_MAPPING.items():\n",
    "    print(f\"\\nüè¢ {company_info['name']} ({ticker}) - {company_info['category']}\")\n",
    "    \n",
    "    company_repos = []\n",
    "    \n",
    "    # Analyze main repository\n",
    "    main_repo_data = collect_repo_intelligence(company_info['main_repo'])\n",
    "    if main_repo_data:\n",
    "        main_repo_data['repo_type'] = 'main'\n",
    "        company_repos.append(main_repo_data)\n",
    "    \n",
    "    # Analyze additional repositories (limit to 2 to manage rate limits)\n",
    "    for additional_repo in company_info['additional_repos'][:2]:\n",
    "        additional_repo_data = collect_repo_intelligence(additional_repo)\n",
    "        if additional_repo_data:\n",
    "            additional_repo_data['repo_type'] = 'additional'\n",
    "            company_repos.append(additional_repo_data)\n",
    "    \n",
    "    company_github_data[ticker] = {\n",
    "        'company_info': company_info,\n",
    "        'repositories': company_repos\n",
    "    }\n",
    "\n",
    "print(f\"\\n‚úÖ Collected data for {len(company_github_data)} companies\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
